{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Box-Plots for Education (DrivenData project)\n",
    "\n",
    "This is a project listed in DrivenData (https://www.drivendata.org/competitions/46/box-plots-for-education-reboot/). The goal is to predict the probability that a certain label is attached to a budget line item.\n",
    "\n",
    "#### Predictors:\n",
    "\n",
    "`FTE` float - If an employee, the percentage of full-time that the employee works. \n",
    "\n",
    "`Facility_or_Department` - If expenditure is tied to a department/facility, that department/facility.\n",
    "\n",
    "`Function_Description` - A description of the function the expenditure was serving.\n",
    "\n",
    "`Fund_Description` - A description of the source of the funds.\n",
    "\n",
    "`Job_Title_Description` - If this is an employee, a description of that employee's job title.\n",
    "\n",
    "`Location_Description` - A description of where the funds were spent.\n",
    "\n",
    "`Object_Description` - A description of what the funds were used for.\n",
    "\n",
    "`Position_Extra` - Any extra information about the position that we have.\n",
    "\n",
    "`Program_Description` - A description of the program that the funds were used for.\n",
    "\n",
    "`SubFund_Description` - More detail on Fund_Description\n",
    "\n",
    "`Sub_Object_Description` - More detail on Object_Description \n",
    "\n",
    "`Text_1` - Any additional text supplied by the district.\n",
    "\n",
    "`Text_2` - Any additional text supplied by the district.\n",
    "\n",
    "`Text_3` - Any additional text supplied by the district.\n",
    "\n",
    "`Text_4` - Any additional text supplied by the district.\n",
    "\n",
    "`Total` float - The total cost of the expenditure. \n",
    "\n",
    "#### Labels:\n",
    "\n",
    "`Function`\n",
    "\n",
    "`Use`\n",
    "\n",
    "`Sharing`\n",
    "\n",
    "`Reporting`\n",
    "\n",
    "`Student_Type`\n",
    "\n",
    "`Position_Type`\n",
    "\n",
    "`Object_Type`\n",
    "\n",
    "`Pre_K`\n",
    "\n",
    "`Operating_Status`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the datasset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('TrainingData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separating the columns into three lists: text predictors, numeric predictors, and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing in a list the categorical columns names\n",
    "LABELS = ['Function', 'Object_Type', 'Operating_Status',\n",
    "          'Position_Type', 'Pre_K', 'Reporting',\n",
    "          'Sharing', 'Student_Type', 'Use']\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Get the columns that are numeric in the original df\n",
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading functions to sample and split into train and test sets for multilabel dataset: (taken from datacamp https://github.com/datacamp/course-resources-ml-with-experts-budgets/blob/master/src/data/multilabel.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total rows on training set is 400,277. Sampling to reduce the computation time of the model to run this enotebook as an example. Then splitting dataset into train and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "from multilable_split import multilabel_sample_dataframe, multilabel_train_test_split\n",
    "\n",
    "# setting size of sample size\n",
    "SAMPLE_SIZE = 50000\n",
    "\n",
    "# taking sample of `SAMPLE_SIZE`\n",
    "sampling = multilabel_sample_dataframe(df,\n",
    "                                       pd.get_dummies(df[LABELS]),\n",
    "                                       size=SAMPLE_SIZE,\n",
    "                                       min_count=25,\n",
    "                                       seed=42)\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(sampling[LABELS])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(sampling[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.3,\n",
    "                                                               min_count=3,\n",
    "                                                               seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all text data into a single string per row so it can be passed to a vectorizer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### funtion to convert all training text data in your DataFrame to a\n",
    "#### single string per row that can be passed to the vectorizer object\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    # `NUMERIC_COLUMNS` and `LABELS` are lists that contain non-text columns\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna('', inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Function Transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns,validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text processing by tokenizing in punctuation to accept just alphanumerical characters and including unigrams and bi-grams. With this `token_pattern` characters like hyphenes between two words will separate the words into two tokens.\n",
    "\n",
    "Parameters used:\n",
    "\n",
    "`token_pattern`: how to split into tokens. Used `'[A-Za-z0-9]+(?=\\\\s+)'` to tokenize only alphanumerical characters.\n",
    "\n",
    "`ngram_range`: number of ngrams to use. Used `(1,2)` to use all ngrams from unigram (1) to bi-gram (2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashing Trick: when wanting to make array of features smaller, specially when using lare amounts of text data. Using Hashing trick can be use with sklearn with `HashingVectorizer` and it replaces `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "vector = HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                           ngram_range=(1,2),\n",
    "                           alternate_sign=False,\n",
    "                           norm=None,\n",
    "                           binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding interaction terms to account for the influence tokens that are not together and therefore not catch by the bi-grams have. For example '2nd grade english teacher' and '2nd grade elementary school english teacher'. Both string have '2nd grade' and 'english teacher' but the second is separated in a range that the ngrams used is not going to group them. so an interaction term will find both tokens are present in the same record and find the influence that has on the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using function `SparseInteractions` that is taken from DataCamp (https://github.com/drivendataorg/box-plots-sklearn/blob/master/src/features/SparseInteractions.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full model takes too much computational time, can't run locally. So for my model I'll use `SelectKBest` to reduce number of features (dimensional reduction) and therefore reduce computational time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from SparseInteractions import SparseInteractions\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# number of best features\n",
    "chi_k = 300\n",
    "\n",
    "# my model\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', SimpleImputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', vector),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('clf', OneVsRestClassifier(RandomForestClassifier(n_estimators=100)))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('union', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('numeric_features', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
       "          func=<function <lambda> at 0x0000027FBDFEA2F0>, inv_kw_args=None,\n",
       "          inverse_func=None...b_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          n_jobs=None))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.7932\n",
      "Logloss score:  1.5872486574372298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.scorer import make_scorer\n",
    "from LogLoss import multi_multi_log_loss\n",
    "\n",
    "# Compute and print accuracy\n",
    "print(\"\\nAccuracy: \",\n",
    "      pl.score(X_test, y_test))\n",
    "\n",
    "# \n",
    "log_loss_scorer = make_scorer(multi_multi_log_loss)\n",
    "\n",
    "# calculate and print the log loss score\n",
    "print(\"Logloss score: \", log_loss_scorer(pl, X_test, y_test.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating predicted probabilities on test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sbeuc\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# loading the test set\n",
    "testset = pd.read_csv('TestData.csv',index_col=0)\n",
    "\n",
    "# calculating the predicted probabilities\n",
    "predictions = pl.predict_proba(testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Function__Aides Compensation</th>\n",
       "      <th>Function__Career &amp; Academic Counseling</th>\n",
       "      <th>Function__Communications</th>\n",
       "      <th>Function__Curriculum Development</th>\n",
       "      <th>Function__Data Processing &amp; Information Services</th>\n",
       "      <th>Function__Development &amp; Fundraising</th>\n",
       "      <th>Function__Enrichment</th>\n",
       "      <th>Function__Extended Time &amp; Tutoring</th>\n",
       "      <th>Function__Facilities &amp; Maintenance</th>\n",
       "      <th>Function__Facilities Planning</th>\n",
       "      <th>...</th>\n",
       "      <th>Student_Type__Special Education</th>\n",
       "      <th>Student_Type__Unspecified</th>\n",
       "      <th>Use__Business Services</th>\n",
       "      <th>Use__ISPD</th>\n",
       "      <th>Use__Instruction</th>\n",
       "      <th>Use__Leadership</th>\n",
       "      <th>Use__NO_LABEL</th>\n",
       "      <th>Use__O&amp;M</th>\n",
       "      <th>Use__Pupil Services &amp; Enrichment</th>\n",
       "      <th>Use__Untracked Budget Set-Aside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180042</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28872</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186915</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412396</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427740</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Function__Aides Compensation  Function__Career & Academic Counseling  \\\n",
       "180042                      0.000000                                0.000000   \n",
       "28872                       0.066667                                0.000000   \n",
       "186915                      0.000000                                0.066667   \n",
       "412396                      0.000000                                0.066667   \n",
       "427740                      0.000000                                0.066667   \n",
       "\n",
       "        Function__Communications  Function__Curriculum Development  \\\n",
       "180042                       0.0                          0.000000   \n",
       "28872                        0.0                          0.066667   \n",
       "186915                       0.0                          0.266667   \n",
       "412396                       0.0                          0.333333   \n",
       "427740                       0.0                          0.066667   \n",
       "\n",
       "        Function__Data Processing & Information Services  \\\n",
       "180042                                               0.2   \n",
       "28872                                                0.0   \n",
       "186915                                               0.0   \n",
       "412396                                               0.0   \n",
       "427740                                               0.0   \n",
       "\n",
       "        Function__Development & Fundraising  Function__Enrichment  \\\n",
       "180042                                  0.0              0.000000   \n",
       "28872                                   0.0              0.800000   \n",
       "186915                                  0.0              0.000000   \n",
       "412396                                  0.0              0.000000   \n",
       "427740                                  0.0              0.066667   \n",
       "\n",
       "        Function__Extended Time & Tutoring  \\\n",
       "180042                                 0.0   \n",
       "28872                                  0.0   \n",
       "186915                                 0.0   \n",
       "412396                                 0.0   \n",
       "427740                                 0.0   \n",
       "\n",
       "        Function__Facilities & Maintenance  Function__Facilities Planning  \\\n",
       "180042                            0.000000                            0.0   \n",
       "28872                             0.000000                            0.0   \n",
       "186915                            0.000000                            0.0   \n",
       "412396                            0.000000                            0.0   \n",
       "427740                            0.133333                            0.0   \n",
       "\n",
       "                     ...                 Student_Type__Special Education  \\\n",
       "180042               ...                                             0.0   \n",
       "28872                ...                                             0.0   \n",
       "186915               ...                                             0.0   \n",
       "412396               ...                                             0.0   \n",
       "427740               ...                                             0.0   \n",
       "\n",
       "        Student_Type__Unspecified  Use__Business Services  Use__ISPD  \\\n",
       "180042                   0.866667                0.133333   0.000000   \n",
       "28872                    0.866667                0.000000   0.000000   \n",
       "186915                   0.400000                0.000000   0.200000   \n",
       "412396                   0.333333                0.000000   0.266667   \n",
       "427740                   0.733333                0.133333   0.066667   \n",
       "\n",
       "        Use__Instruction  Use__Leadership  Use__NO_LABEL  Use__O&M  \\\n",
       "180042          0.733333         0.133333       0.066667  0.000000   \n",
       "28872           0.133333         0.000000       0.200000  0.066667   \n",
       "186915          0.266667         0.000000       0.200000  0.000000   \n",
       "412396          0.266667         0.000000       0.266667  0.000000   \n",
       "427740          0.066667         0.066667       0.000000  0.000000   \n",
       "\n",
       "        Use__Pupil Services & Enrichment  Use__Untracked Budget Set-Aside  \n",
       "180042                               0.0                              0.0  \n",
       "28872                                0.8                              0.0  \n",
       "186915                               0.0                              0.0  \n",
       "412396                               0.0                              0.0  \n",
       "427740                               0.2                              0.0  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# storing the predictions in the format required\n",
    "predictions_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS],prefix_sep='__').columns, \n",
    "                              index=testset.index,\n",
    "                              data=predictions)\n",
    "\n",
    "# storing predictions in a csv file to upload\n",
    "predictions_df.to_csv('predictions.csv')\n",
    "\n",
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try to improve\n",
    "\n",
    "- vector: `FeatureHasher`, `CountVectorizer`, `HashingVectorizer`, with new parameters (ngrams and tokkenizing)\n",
    "- change `chi_k`(increase)\n",
    "- more data on sample (increase)\n",
    "- increase nclassifiers in random forest\n",
    "- try other classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "vector = FeatureHasher(n_features=1048576,\n",
    "                       alternate_sign=False)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                         ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1:\n",
    "- SAMPLE_SIZE = 50000\n",
    "- `chi_k` = 500\n",
    "- RandomForestClassifier - n_estimators=15\n",
    "\n",
    "Accuracy:  0.7748\n",
    "Logloss score:  1.640719800152314\n",
    "\n",
    "Run 2:\n",
    "- SAMPLE_SIZE = 50000\n",
    "- `chi_k` = 500\n",
    "- RandomForestClassifier - n_estimators=100\n",
    "\n",
    "Accuracy:  0.7932\n",
    "Logloss score:  1.5872486574372298\n",
    "\n",
    "Run 3:\n",
    "- SAMPLE_SIZE = 200000\n",
    "- `chi_k` = 500\n",
    "- RandomForestClassifier - n_estimators=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
